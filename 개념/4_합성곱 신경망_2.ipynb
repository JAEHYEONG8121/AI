{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN모델 구현, 학습 및 결과 확인\n",
    "> 간단한 CNN을 구현해보자. 먼저 필요한 모듈을 불러오고 hyperparameter를 설정하는 부분이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)\n",
    "\n",
    "batch_size = 256\n",
    "learning_rate = 0.0002\n",
    "num_epoch = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 새롭게 사용하는 모듈은 torch.utils.data에 있는 DataLoader모듈과 torchvision의 dataset, transforms이다.\n",
    "- 모델을 학습하기 위해서는 지속적으로 데이터를 모델에 전달해야 한다. 또한 <font color=blue>데이터를 하나씩 전달하지 않고 원하는 batch_size대로 묶어서 전달하거나 더 효율적인 학습을 위해 데이터를 어떤 규칙에 따라 정렬하거나 섞거나 해야하는데</font>, 이런 역할을 해주는 것이 바로 <font color = gold>DataLoader</font>모듈이다!\n",
    "- <font color = gold>torchvision</font>은 유명한 영상처리용 데이터셋, 모델, 이미지 변환기가 들어있는 패키지로서, 여기서 dataset모듈은 데이터를 읽어오는 역할, transforms는 불러온 이미지를 필요에 따라 변환해주는 역할을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.ToTensor(),\n",
    "                         target_transform=None, download=True)\n",
    "mnist_test = dset.MNIST(\"./\", train=False, transform=transforms.ToTensor(),\n",
    "                        target_transform=None, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size,\n",
    "                                           shuffle=True,num_workers=2, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2, drop_last=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. MNIST 데이터 베이스\n",
    "    - 가로 세로 길이 28의 숫자 이미지로 이루어진 데이터셋이다.\n",
    "    - 각 숫자는 0부터 9까지 손으로 쓴 이미지이다.\n",
    "    - dset.MNIST 함수에서 첫 번째 인수 : 데이터의 경로\n",
    "        - 경로로 \"./\"를 사용했는데 이는 현재 코드가 있는 위치를 경로로 사용하겠다는 의미이다.\n",
    "    - 두 번째 인수 : train\n",
    "        - True를 넣으면 학습 데이터를 불러오고 False를 넣으면 테스트 데이터를 불러온다.\n",
    "    - 세 번째 인수 : transform\n",
    "        - 이미지에 대한 변형인데, 이미지 데이터를 파이토치 텐서로 변환하는 transforms.ToTensor()가 들어가 있다.\n",
    "    - 네 번째 인수 : target_transform\n",
    "        - 이미지에 해당하는 라벨에 대한 변형을 의미한다.\n",
    "        - MNIST 데이터는 이미지와 그 이미지에 해당하는 라벨 카테고리 즉, 0~9까지 숫자 중 하나가 매칭이 되어 있다.\n",
    "    - 마지막 인수 : download\n",
    "        - 현재 경로에 MNIST 데이터가 없을 경우 다운로드하겠다는 의미이다. </br></br>\n",
    "\n",
    "2. DataLoader 부분\n",
    "    - dset.MNIST를 통해 정리된 데이터를 batch_size 개수만큼 묶는다는 의미이다.\n",
    "    - 셔플 여부(shuffle), 데이터를 묶을 때 사용할 프로세스 개수(num_workers), 묶고 남는 데이터는 버릴지 여부(drop_last) 등에 대한 설정이다.\n",
    "\n",
    "- 이렇게 생성된 train_loader와 test_loader는 순차적으로 모델에 데이터를 전달해준다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***CNN 모델 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*3*3, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        out = self.layer(x)\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = self.fc_layer(out)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 클래스 안에 모델의 각 연산들이 정의되어 있고, 또한 forward함수에서 연산들을 순차적으로 실행하여 결과값만 리턴하도록 정의되어 있다.\n",
    "\n",
    "- __init__함수에 있는 super클래스는 CNN클래스의 부모 클래스인 nn.Module을 초기화하는 역할을 한다.\n",
    "\n",
    "- 합성곱 연산은 nn.Conv2d함수를 통해 이루어지는데, 인수로는 in_channels, out_channels, kernel_size, stride, padding등이 있다.\n",
    "    - in_channels, out_channels : 앞서 합성곱 연산의 3차원적 이해에서 RGB 3 채널 데이터를 입력으로 받았던 것을 예로 들면 in_channels에는 3이 들어가게 되고, 필터의 개수가 out_channels에 들어가게 된다. \n",
    "    - 배치까지 포함된 텐서의 형태로 생각하면 입력은 [batch_size, in_channels, 가로, 세로]가 되고 합성곱 연산의 결과는 [batch_size, out_channels, 가로, 세로]가 된다.\n",
    "    - 현재 사용하는 MNIST 데이터셋은 [batch_size, 1, 가로, 세로]의 형태이므로 CNN클래스에서 첫 번째 연산을 nn.Conv2d(1, 16, 5)로 설정하였다. -> in_channels = 1, out_channels = 16, kernel_size = 5\n",
    "</br></br>\n",
    "- [batch_size, 1, 28, 28]이었던 입력값은 첫 nn.Conv2d(1, 16, 5)연산을 통과하여 [batch_size, 16, 24, 24]가 된다.\n",
    "    - 필터(패널)의 크기 K = 5, 패딩은 없으므로 P = 0, 스트라이드는 따로 설정하지 않았으므로 기본값 S = 1이다.\n",
    "\n",
    "    ![CNN13](img/CNN13.png)\n",
    "\n",
    "- 위의 결과 텐서를 활설 함수인 nn.ReLU()에 넣어준다. 이 과정을 다시 한번 반복하여 nn.Conv2d(16, 32, 5), nn.ReLU()연산을 통과하면 [batch_size, 32, 20, 20]이 된다.\n",
    "\n",
    "- 그 다음에는 nn.MaxPool2d(2, 2)연산이 나온다. 이 연산은 인수로 kernel_size, stride, padding등을 받는다\n",
    "    - kernel_size : 풀링 연산을 할 때 한 번에 훑는 영역의 크기이다. 하나의 숫자 k를 전달하면 kxk 영역에서 풀링한다.\n",
    "    - stride : 이동거리</br>\n",
    "    -> 예제처럼 kernel_size = 2, stride = 2를 전달하면 2x2 영역에서 풀링하고 2만큼 이동하므로, 연산 후에는 텐서가 반으로 줄어들게 된다! 결과적으로 텐서는 [batch_size, 32, 10, 10]의 크기가 된다.</br></br>\n",
    "\n",
    "- 그 이후의 연산 nn.Conv2d(32, 64, 5), nn.ReLU(), nn.MaxPool2d(2, 2)가 실행되면 텐서의 크기는 [batch_size, 64, 6, 6] -> [batch_size, 64, 3, 3]이 된다!\n",
    "\n",
    "- 그 다음부터는 인공 신경망에서 했던 것처럼 Linear함수를 통해 10개의 카테고리로 뉴런의 수를 줄여나간다.\n",
    "\n",
    "- forward함수\n",
    "    - [batch_size, 64, 3, 3] 형태의 텐서를 view함수를 통해 바꾸어준다.\n",
    "    - view 함수에 인수로 목표하는 새로운 형태 [batch_size, -1]을 전달한다. 여기서 -1은 -1인 부분을 알아서 계산하라는 의미를 가진다.\n",
    "    - 이렇게 형태를 바꾸어주는 이유는 합성곱 연산에서 요구되는 텐서의 형태와 Linear연산에서 요구되는 텐서의 형태가 다르기 때문이다.\n",
    "    - 형태가 바뀐 텐서에 nn.Linear(64 * 3 * 3, 100), nn.ReLU(), nn.Linear(100, 10)연산을 차례대로 실행하면 [batch_size, 10] 형태의 텐서가 나온다.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 지금까지 봤던 코드처럼 모델을 초기화하고, '교차 엔트로피 손실 함수'를 지정하자.\n",
    "- 최적화 함수로는 SGD를 사용해도 되지만, 새롭게 Adam알고리즘을 사용해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(DEVICE)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0389, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_arr = []\n",
    "\n",
    "for i in range(num_epoch) :\n",
    "    for j, [image,label] in enumerate(train_loader) :\n",
    "        x = image.to(DEVICE)\n",
    "        y = label.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_func(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if j % 1000 == 0 :\n",
    "            print(loss)\n",
    "            loss_arr.append(loss.cpu().detach().numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- enumerate()함수 : 인덱스와 원소를 동시에 접근하며 루프를 돌릴 수 있게 한다.\n",
    "    - j가 인덱스(순서)를 담고, train 데이터의 image와 label을 각각 받아주었다.\n",
    "    - image는 x에다가, label은 y에다가 저장하였다.</br></br>\n",
    "\n",
    "- train_loader에서 image와 label쌍을 batch_size만큼 받아와서 모델에 전달하고, 손실을 계산하고, 손실에 대한 경사하강법을 진행하여 모델을 업데이트한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_arr)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 시의 손실을 시각화 한 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 98.8681869506836\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad() :\n",
    "    for image, label in test_loader :\n",
    "        x = image.to(DEVICE)\n",
    "        y_ = label.to(DEVICE)\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        _, output_index = torch.max(output, 1)\n",
    "        \n",
    "        total += label.size(0)\n",
    "        correct += (output_index == y_).sum().float()\n",
    "        \n",
    "    print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 맞은 개수, 전체 개수를 담당할 변수를 각각 correct와 total로 지정하고 0으로 초기화한다.\n",
    "- torch.no_grad()는 기울기를 계산하지 않는다는 의미이다. 이 조건하에 테스트를 진행한다.\n",
    "- 모델에 test 데이터를 넣어서 나온 결과를 torch.max()함수를 이용하여 최댓값과 그 인덱스를 구한다.\n",
    "    - output은 (batch_size x 10)'(배치 크기) x (클래스의 개수)'의 크기로 나올 것이다. 열은 클래스를 의미하므로, 최댓값을 갖는 열의 인덱스를 추출해낸 것이다.\n",
    "- 그리고 그 인덱스가 정답 라벨과 일치하는지에 따라 correct변수에 더해준다.\n",
    "- total변수에는 라벨의 형태(size)의 0번쨰 인덱스 값은 batch_size에 해당하기 때문에 이를 전부 더해준다.\n",
    "- 모든 test 데이터를 모델에 통과하여 이 값들을 얻고, 마지막에 정확도를 출력한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52d90d3cc821dd0beedd6e719dbdecc722c226b9d90ed1b663c34e1877f1142e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
